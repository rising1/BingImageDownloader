{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heartbeat2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rising1/BingImageDownloader/blob/master/Heartbeat2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIrbysuSaF7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#a = []\n",
        "#while(1):\n",
        "#   a.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cQoh-wCtQZm",
        "colab_type": "code",
        "outputId": "65b351b6-edf0-434e-8861-e4ab9f78249c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install google_images_download"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Collecting google_images_download\n",
            "  Downloading https://files.pythonhosted.org/packages/18/ed/0319d30c48f3653802da8e6dcfefcea6370157d10d566ef6807cceb5ec4d/google_images_download-2.8.0.tar.gz\n",
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium->google_images_download) (1.24.3)\n",
            "Building wheels for collected packages: google-images-download\n",
            "  Building wheel for google-images-download (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-images-download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14550 sha256=481564dbd02c166217d1736f85173b67c6eec9e99a3199c6998387a0428ef51c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/28/ad/f56e7061e1d2a9a1affe2f9c649c2570cb9198dd24ede0bbab\n",
            "Successfully built google-images-download\n",
            "Installing collected packages: selenium, google-images-download\n",
            "Successfully installed google-images-download-2.8.0 selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD4Mn073a2dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/rising1/Heartbeat.git\n",
        "#%cd Heartbeat\n",
        "#%ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cy2bnZD87BL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "#!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "#!pip install gputil\n",
        "#!pip install psutil\n",
        "#!pip install humanize\n",
        "#import psutil\n",
        "#import humanize\n",
        "#import os\n",
        "#import GPUtil as GPU\n",
        "#GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "#gpu = GPUs[0]\n",
        "#def printm():\n",
        "# process = psutil.Process(os.getpid())\n",
        "# print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "# print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Osdprdz0ImD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import needed packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import os, csv\n",
        "import glob\n",
        "from torchvision import transforms, datasets\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "import io\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class test_images():\n",
        "\n",
        "    def __init__(self,batch_size,shuffle_data):\n",
        "        global data_transform\n",
        "        self.batch_sizes = batch_size\n",
        "        self.shuffle_data = shuffle_data\n",
        "        data_transform = transforms.Compose([\n",
        "                    transforms.Resize(128),\n",
        "                    # transforms.CenterCrop(72),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "    def get_tensor(self,image_bytes):\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        return data_transform(image).unsqueeze(0)\n",
        "\n",
        "\n",
        "    def data_transformation(self,image):\n",
        "        global data_transform\n",
        "        print(\"type(image)=\",type(image))\n",
        "        image_dataset = datasets.ImageFolder(image, data_transform)\n",
        "        return image_dataset\n",
        "\n",
        "    def eval_test(self,path_to_images):\n",
        "        self.dir_path = path_to_images\n",
        "        self.image_dataset = datasets.ImageFolder(self.dir_path+'/eval',data_transform)\n",
        "        self.dataloaders = torch.utils.data.DataLoader(self.image_dataset,\n",
        "                            batch_size=self.batch_sizes,\n",
        "                            shuffle=self.shuffle_data,\n",
        "                            num_workers=0)\n",
        "\n",
        "        #print(type(self.dataloaders[\"train\"][0]))\n",
        "        self.dataset_sizes = len(self.image_dataset)\n",
        "        return self.dataloaders\n",
        "\n",
        "    def getitem(self, index):\n",
        "        return self.image_dataset.__getitem__(index)   # return image path\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx6qeC4cwFlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model,my_test_loader,validate_path):\n",
        "    bird_list = ['Owl', 'Bittern', 'Blackbird', 'Tit', 'Chicken', 'Parakeet', 'Peregrine', 'Dove', 'Plover',\n",
        "                 'Puffin', 'Robin', 'sparrowhawk']\n",
        "    my_test_loader_eval = my_test_loader.eval_test(dataPathRoot)\n",
        "    model.eval()\n",
        "    test_acct = 0.0\n",
        "    test_history = []\n",
        "    image_list = []\n",
        "    label_list = []\n",
        "    predictions_list = []\n",
        "    images, labels = next(iter(my_test_loader_eval))\n",
        "    if torch.cuda.is_available():\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "    #  Predict classes using images from the test set\n",
        "    outputs = model(images)\n",
        "    _, prediction = torch.max(outputs.data, 1)\n",
        "    for image in images:\n",
        "        image = image.cpu()\n",
        "        image_list.append(imshow(image))\n",
        "    for i in range(len(prediction)):\n",
        "        if (birds_listing(validate_path)[int(prediction[i].cpu().numpy())]) == (\n",
        "                bird_list[labels.data[i].cpu().numpy()]):\n",
        "                tick = \"Yes\"    # str(u'\\2714'.encode('utf-8')) # approval tick mark\n",
        "        else:\n",
        "                tick = \"No\"     # str(u'\\2717'.encode('utf-8')) # cross mark\n",
        "        predictions_list.append(birds_listing(validate_path)[int(prediction[i].cpu().numpy())]  +\n",
        "                                \"\\n\" + \"\\n\" + \"       \" + tick)\n",
        "                                # \"\\n\" + bird_list[labels.data[i].cpu().numpy()] + \" \" + tick)\n",
        "    show_images(image_list,2,predictions_list)\n",
        "\n",
        "def show_images(images, cols=1, titles=None):\n",
        "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
        "\n",
        "    Parameters\n",
        "    ---------\n",
        "    images: List of np.arrays compatible with plt.imshow.\n",
        "\n",
        "    cols (Default = 1): Number of columns in figure (number of rows is\n",
        "                        set to np.ceil(n_images/float(cols))).\n",
        "\n",
        "    titles: List of titles corresponding to each image. Must have\n",
        "            the same length as titles.\n",
        "    \"\"\"\n",
        "    assert ((titles is None) or (len(images) == len(titles)))\n",
        "    n_images = len(images)\n",
        "    if titles is None: titles = ['Image (%d)' % i for i in range(1, n_images + 1)]\n",
        "    fig = plt.figure()\n",
        "    for n, (image, title) in enumerate(zip(images, titles)):\n",
        "        a = fig.add_subplot(cols, np.ceil(n_images / float(cols)), n + 1)\n",
        "        if image.ndim == 2:\n",
        "            plt.gray()\n",
        "        plt.imshow(image)\n",
        "        a.set_title(title,fontsize=8)\n",
        "    #  fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
        "    #  fig = plt.figure(figsize=(6, 3))\n",
        "    plt.show(block=False)\n",
        "    plt.pause(8)\n",
        "    plt.close()\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    image_list = []\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    return inp\n",
        "\n",
        "def birds_listing(validate_path):\n",
        "    with open(validate_path,'r') as f:\n",
        "       #  with open('C:/Users/phfro/Documents/python/data/Class_validate.txt', 'r') as f:\n",
        "       #  with open('/content/drive/My Drive/Colab Notebooks/Class_validate.txt', 'r') as f:\n",
        "       reader = csv.reader(f)\n",
        "       classes = list(reader)[0]\n",
        "       classes.sort()\n",
        "       #  self.classes = open('/content/drive/My Drive/Colab Notebooks/Class_validate.txt').read()\n",
        "       #  print(\"self.classes=\",classes)\n",
        "       #  print(\"len self.classes=\",len(classes))\n",
        "    return classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjcmKbxmD7Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transforms to apply to the datan\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torch\n",
        "import csv\n",
        "import os\n",
        "\n",
        "\n",
        "class HawkLoader:\n",
        "    def __init__(self, dir_path, batch_sizes, pic_size, computer):\n",
        "        self.batch_sizes = batch_sizes\n",
        "        self.dir_path = dir_path\n",
        "        self.pic_size = pic_size\n",
        "        data_transforms = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.Resize(224),\n",
        "                transforms.RandomResizedCrop(self.pic_size),\n",
        "                # transforms.CenterCrop(self.pic_size),\n",
        "                # transforms.RandomResizedCrop(self.pic_size),\n",
        "                # transforms.CenterCrop(self.pic_size),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(224),\n",
        "                transforms.CenterCrop(self.pic_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "            'test': transforms.Compose([\n",
        "                transforms.Resize(224),\n",
        "                transforms.CenterCrop(self.pic_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "        }\n",
        "\n",
        "        # transforms.RandomResizedCrop(120,(1,1),(1,1),2),\n",
        "        # print(os.path.join(self.dir_path, 'train'))\n",
        "        if (computer == \"home_laptop\" or computer == \"home_red_room\" ):\n",
        "            image_datasets = {x: datasets.ImageFolder(os.path.join(self.dir_path, x),\n",
        "                              data_transforms[x]) for x in ['train', 'val', 'test']}\n",
        "        elif computer == \"work\":\n",
        "            image_datasets = {x: datasets.ImageFolder(os.path.join('D:/', x),\n",
        "                              data_transforms[x]) for x in ['train', 'val', 'test']}\n",
        "        self.dataloaderTrain = {x: torch.utils.data.DataLoader(\n",
        "                            image_datasets[x],\n",
        "                            batch_size=self.batch_sizes,\n",
        "                            shuffle=True, num_workers=4)\n",
        "                       for x in ['train']}\n",
        "        self.dataloaderTest = {x: torch.utils.data.DataLoader(\n",
        "                            image_datasets[x],\n",
        "                            batch_size=self.batch_sizes,\n",
        "                            shuffle=False, num_workers=4)\n",
        "                       for x in [ 'val', 'test']}\n",
        "        #print(type(self.dataloaders[\"train\"][0]))\n",
        "        self.dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "\n",
        "        #  self.classes = open('BirdList.txt').read().splitlines()\n",
        "        #  self.classesTest = ('buzzard', 'golden eagle','kestrel', 'peregrine falcon',\n",
        "        #                    'red kite', 'sparrow hawk')\n",
        "\n",
        "    def birds_listing(self):\n",
        "        with open('/content/drive/My Drive/Colab Notebooks/Class_validate.txt', 'r') as f:\n",
        "           reader = csv.reader(f)\n",
        "           self.classes = list(reader)[0]\n",
        "           self.classes.sort()\n",
        "           #  self.classes = open('/content/drive/My Drive/Colab Notebooks/Class_validate.txt').read()\n",
        "           #  print(\"self.classes=\",self.classes)\n",
        "           #  print(\"len self.classes=\",len(self.classes))\n",
        "        return self.classes\n",
        "\n",
        "    def cifar10_train_loader(self):\n",
        "        # Define transformations for the training set, flip the images randomly, crop out and apply mean and std normalization\n",
        "        train_transformations = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        # Load the training set\n",
        "        train_set = CIFAR10(root=\"./data\", train=True, transform=train_transformations, download=True)\n",
        "\n",
        "        # Create a loder for the training set\n",
        "        train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=0)\n",
        "        print (\"returning train loader object\")\n",
        "        return train_loader\n",
        "\n",
        "    def cifar10_test_loader(self):\n",
        "        # Define transformations for the test set\n",
        "        test_transformations = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "        ])\n",
        "\n",
        "        # Load the test set, note that train is set to False\n",
        "        test_set = CIFAR10(root=\"./data\", train=False, transform=test_transformations, download=True)\n",
        "\n",
        "        # Create a loder for the test set, note that both shuffle is set to false for the test loader\n",
        "        test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=0)\n",
        "        return test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH5mek906nZR",
        "colab_type": "code",
        "outputId": "521778a7-99c6-4d10-b238-0499ae29b8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Import needed packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import os, csv\n",
        "import glob\n",
        "\n",
        "# Hyper-parameters\n",
        "colour_channels = 3  # used in SimpleNet\n",
        "no_feature_detectors = 128 # used in Unit\n",
        "kernel_sizes = 3  # used in Unit\n",
        "stride_pixels = 1  # used in Unit\n",
        "padding_pixels = 1  # used in Unit\n",
        "pooling_factor = 2  # used in SimpleNet\n",
        "pic_size = 128 # used in SimpleNet\n",
        "output_classes = 220  # used in SimpleNet\n",
        "learning_rate = 0.0001  # used in HeartbeatClean\n",
        "decay_cycles = 1  # default to start\n",
        "weight_decay = 0.0001  # used in HeartbeatClean\n",
        "dropout_factor = 0.0  # used in Unit\n",
        "flattener = 64\n",
        "faff = 'false'\n",
        "linear_mid_layer = 1024\n",
        "num_epochs = 200  # used in HeartbeatClean\n",
        "snapshot_points = num_epochs / 1\n",
        "batch_sizes = 48 # used in HeartbeatClean\n",
        "#  batch_sizes = 6 # used in HeartbeatClean\n",
        "loadfile = True\n",
        "\n",
        "validate_path = '/content/drive/My Drive/Colab Notebooks/Class_validate.txt'\n",
        "dataPathRoot = '/content/drive/My Drive/Colab Notebooks'\n",
        "# dataPathRoot = 'C:/Users/phfro/PycharmProjects/Heartbeat'\n",
        "#dataPathRoot = 'E:/'\n",
        "# validate_path = 'C:/Users/phfro/PycharmProjects/Heartbeat/Class_validate.txt'\n",
        "#alidate_path = 'E:/Class_validate.txt'\n",
        "computer = \"home_laptop\"\n",
        "# deploy_test = Hawknet_Depld.test_images(12, False)\n",
        "# Check if gpu support is available\n",
        "cuda_avail = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Args lists to pass through to models\n",
        "UnitArgs = [kernel_sizes, stride_pixels, padding_pixels]\n",
        "SimpleNetArgs = [UnitArgs, dropout_factor,output_classes, \n",
        "                 colour_channels, no_feature_detectors, \n",
        "                 pooling_factor]\n",
        "\n",
        "\n",
        "class Unit(nn.Module):\n",
        "    def __init__(self, UnitArgs, in_channel, out_channel):\n",
        "        \n",
        "        super(Unit, self).__init__()\n",
        "        self.conv = nn.Conv2d( kernel_size = UnitArgs[0], stride = UnitArgs[1],\n",
        "                               padding = UnitArgs[2],\n",
        "                               in_channels = in_channel, out_channels = out_channel)\n",
        "        self.bn = nn.BatchNorm2d(num_features=out_channel)\n",
        "        # self.do = nn.Dropout(dropout_factor)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "        output = self.bn(output)\n",
        "        # output = self.do(output)\n",
        "        output = self.relu(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, SimpleNetArgs):\n",
        "        super(SimpleNet, self).__init__()\n",
        "\n",
        "        # Break out the parameters for the model\n",
        "        UnitArgs = SimpleNetArgs[0]\n",
        "        dropout_factor = SimpleNetArgs[1]\n",
        "        output_classes = SimpleNetArgs[2]\n",
        "        colour_channels = SimpleNetArgs[3]\n",
        "        no_feature_detectors = SimpleNetArgs[4]\n",
        "        pooling_factor = SimpleNetArgs[5]\n",
        "\n",
        "\n",
        "        # Create 14 layers of the unit with max pooling in between\n",
        "        self.unit1 = Unit(UnitArgs,colour_channels, no_feature_detectors)\n",
        "        self.unit2 = Unit(UnitArgs,no_feature_detectors, no_feature_detectors)\n",
        "        self.unit3 = Unit(UnitArgs,no_feature_detectors, no_feature_detectors)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit4 = Unit(UnitArgs,no_feature_detectors, no_feature_detectors * 2)\n",
        "        self.unit5 = Unit(UnitArgs,no_feature_detectors * 2, no_feature_detectors * 2)\n",
        "        self.unit6 = Unit(UnitArgs,no_feature_detectors * 2, no_feature_detectors * 2)\n",
        "        self.unit7 = Unit(UnitArgs,no_feature_detectors * 2, no_feature_detectors * 2)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit8 = Unit(UnitArgs,no_feature_detectors * 2, no_feature_detectors * 4)\n",
        "        self.unit9 = Unit(UnitArgs,no_feature_detectors * 4, no_feature_detectors * 4)\n",
        "        self.unit10 = Unit(UnitArgs,no_feature_detectors * 4, no_feature_detectors * 4)\n",
        "        self.unit11 = Unit(UnitArgs,no_feature_detectors * 4, no_feature_detectors * 4)\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit12 = Unit(UnitArgs,no_feature_detectors * 4, no_feature_detectors * 4)\n",
        "        self.unit13 = Unit(UnitArgs,no_feature_detectors * 4, no_feature_detectors * 4)\n",
        "        self.unit14 = Unit(UnitArgs,no_feature_detectors * 4, no_feature_detectors * 4)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
        "\n",
        "        # Add all the units into the Sequential layer in exact order\n",
        "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4, self.unit5, self.unit6\n",
        "                                 , self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11, self.pool3,\n",
        "                                 self.unit12, self.unit13, self.unit14, self.avgpool)\n",
        "        self.fc = nn.Linear(no_feature_detectors * flattener, output_classes)\n",
        "        #self.fc = nn.Linear(no_feature_detectors * 4 * 4, output_classes)\n",
        "        # self.fc = nn.Linear(no_feature_detectors * 4 , output_classes)\n",
        "        # self.fc = nn.Linear(int (no_feature_detectors / 4), output_classes)\n",
        "        # self.fc_final = nn.Linear(linear_mid_layer, output_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.net(input)\n",
        "        # print(\"net(input) \",output.shape)\n",
        "        output = output.view(-1, no_feature_detectors * flattener )\n",
        "        #output = output.view(-1, no_feature_detectors * 4 * 4)\n",
        "        # output = output.view(-1, no_feature_detectors * 4 )\n",
        "        # output = output.view(-1, int(no_feature_detectors / 4))\n",
        "        #print(\"output.view \",output.shape)\n",
        "        output = self.fc(output)\n",
        "        #output = self.fc_final(output)\n",
        "        #print(\"fc(output) \",output.shape)\n",
        "        return output\n",
        "\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "def first_learning_rate(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "        print(\"learning rate adjusted to \", lr)\n",
        "\n",
        "\n",
        "def lr_decay_cycles(cycles):\n",
        "    global decay_cycles\n",
        "    decay_cycles = cycles\n",
        "    return decay_cycles\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every decay epochs\"\"\"\n",
        "    global decay_cycles\n",
        "    learning_rate = get_lr(optimizer) * (0.1 ** (epoch // decay_cycles))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = learning_rate\n",
        "\n",
        "\n",
        "def get_latest_file(path, *paths):\n",
        "    \"\"\"Returns the name of the latest (most recent) file\n",
        "    of the joined path(s)\"\"\"\n",
        "    fullpath = os.path.join(path, *paths)\n",
        "    list_of_files = glob.glob(fullpath)  # You may use iglob in Python3\n",
        "    if not list_of_files:                # I prefer using the negation\n",
        "        return None                      # because it behaves like a shortcut\n",
        "    latest_file = max(list_of_files, key=os.path.getctime)\n",
        "    _, filename = os.path.split(latest_file)\n",
        "    return filename\n",
        "\n",
        "def load_latest_saved_model(chosen_model = None,is_eval = False):\n",
        "    global dataPathRoot, loadfile, model, optimizer, \\\n",
        "            epoch, loss, device\n",
        "    # load a saved model if one exists\n",
        "    comp_root = dataPathRoot + \"/saved_models/\"\n",
        "\n",
        "    if chosen_model is not None:\n",
        "        selected_model = chosen_model\n",
        "        print(\"looking for \",comp_root + selected_model)\n",
        "        print(\"exists = \",os.path.isfile(comp_root + selected_model))\n",
        "    else:\n",
        "        stub_name = \"Birdies_model_*\"\n",
        "        selected_model = get_latest_file(comp_root, stub_name)\n",
        "        print(\"latest filename=\", selected_model)\n",
        "\n",
        "    if os.path.isfile(comp_root + selected_model) and loadfile == True:\n",
        "        checkpoint = torch.load(comp_root +  selected_model,map_location='cpu')\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        for state in optimizer.state.values():\n",
        "            for k, v in state.items():\n",
        "                if isinstance(v, torch.Tensor):\n",
        "                    state[k] = v.to(device)\n",
        "        epoch = checkpoint['epoch']\n",
        "        loss = checkpoint['loss']\n",
        "        #  model.train()\n",
        "        if not is_eval:\n",
        "            model_file_path = comp_root + selected_model\n",
        "            interim_fig_prev_text = model_file_path[(model_file_path.rfind('_') + 1):(len(model_file_path) - 6)]\n",
        "            interim_fig_prev = float(interim_fig_prev_text)\n",
        "            print(\"using saved model \", model_file_path, \" Loss: {:.4f}\".format(interim_fig_prev))\n",
        "    else:\n",
        "        print(\"using new model\")\n",
        "    #  finished deciding where the model comes from\n",
        "\n",
        "    #  For the given model\n",
        "\n",
        "    #  Print model's state_dict\n",
        "    #  print(\"Model's state_dict:\")\n",
        "    #  for param_tensor in model.state_dict():\n",
        "    #    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "    # Print optimizer's state_dict\n",
        "    print(\"Optimizer's state_dict:\")\n",
        "    for var_name in optimizer.state_dict():\n",
        "        if var_name == \"param_groups\":\n",
        "            print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
        "    first_learning_rate(optimizer,learning_rate)\n",
        "    print(\"model loaded\")\n",
        "\n",
        "batch_size = batch_sizes\n",
        "\n",
        "#Load the training set\n",
        "#train_set = CIFAR10(root=\"./data\", train=True, #transform=train_transformations, download=True)\n",
        "#Create a loder for the training set\n",
        "#train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, #num_workers=4)\n",
        "\n",
        "#Define transformations for the test set\n",
        "#test_transformations = transforms.Compose([\n",
        "# transforms.ToTensor(),\n",
        "# transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "#])\n",
        "# Load the test set, note that train is set to False\n",
        "#test_set = CIFAR10(root=\"./data\", train=False, transform=test_transformations, #download=True)\n",
        "\n",
        "# Create a loder for the test set, note that both shuffle is set to false for #the test loader\n",
        "#test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, #num_workers=4)\n",
        "\n",
        "loader = HawkLoader(dataPathRoot,batch_size,\n",
        "                                    pic_size, computer)\n",
        "train_loader = loader.dataloaderTrain['train']\n",
        "test_loader = loader.dataloaderTest['val']\n",
        "train_size = loader.dataset_sizes['train']\n",
        "test_size = loader.dataset_sizes['val']\n",
        "\n",
        "# Check if gpu support is available\n",
        "cuda_avail = torch.cuda.is_available()\n",
        "\n",
        "# Create model, optimizer and loss function\n",
        "model = SimpleNet(SimpleNetArgs)\n",
        "\n",
        "if cuda_avail:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Create a learning rate adjustment function that divides the learning rate by 10 every 30 epochs\n",
        "def adjust_learning_rate(epoch):\n",
        "    lr = get_lr(optimizer)\n",
        "\n",
        "    if epoch == 180:\n",
        "        lr = lr / 2\n",
        "    elif epoch == 150:\n",
        "        lr = lr / 2\n",
        "    elif epoch == 120:\n",
        "        lr = lr / 2\n",
        "    elif epoch == 90:\n",
        "        lr = lr / 2\n",
        "    elif epoch == 60:\n",
        "        lr = lr / 2\n",
        "    elif epoch == 30:\n",
        "        lr = lr / 2\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "\n",
        "#def save_models(epoch,test_corrects):\n",
        "#    torch.save(model.state_dict(), \"cifar10model\" + test_corrects +\"_{}.model\".format(epoch))\n",
        "#    print(\"Checkpoint saved\")\n",
        "\n",
        "def save_models(epoch, loss, save_point):\n",
        "    print(\"save path types = \",str(type(dataPathRoot))+\"\\t\",str(type(epoch))+\"\\t\",str(type(save_point)))\n",
        "    save_PATH = dataPathRoot + \"/saved_models/\" + \"Birdies_model_{}_\".format(epoch) + \"_best_\" \\\n",
        "                                + str(save_point) + \"_FDpsBSksFn_\" + str(no_feature_detectors) + \"_\" +\\\n",
        "                str(pic_size) + \"_\" + str(batch_size) + \"_\" + str(kernel_sizes) + \"_\" + str(flattener) +\".model\"\n",
        "    checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }\n",
        "    torch.save(checkpoint, save_PATH)\n",
        "    print(\"Checkpoint saved\")\n",
        "    if (os.path.exists(save_PATH)):\n",
        "        print(\"verified save \", save_PATH)\n",
        "\n",
        "\n",
        "def test():\n",
        "    global test_acc, test_acc_abs\n",
        "    model.eval()\n",
        "    test_acc_abs = 0\n",
        "    test_acc = 0.0\n",
        "    for i, (images, labels) in enumerate(test_loader):\n",
        "\n",
        "        if cuda_avail:\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "\n",
        "        # Predict classes using images from the test set\n",
        "        outputs = model(images)\n",
        "        _, prediction = torch.max(outputs.data, 1)\n",
        "        # prediction = prediction.cpu()\n",
        "        test_acc_abs += torch.sum(prediction == labels.data)\n",
        "\n",
        "    # Compute the average acc and loss over all 10000 test images\n",
        "    test_acc = test_acc_abs.cpu().numpy() / test_size\n",
        "    return (test_acc, test_acc_abs)\n",
        "\n",
        "\n",
        "def train(num_epochs):\n",
        "    global best_acc, train_acc, train_loss\n",
        "    best_acc = 0\n",
        "\n",
        "    since = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_acc = 0.0\n",
        "        train_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            # Move images and labels to gpu if available\n",
        "            if cuda_avail:\n",
        "                images = Variable(images.cuda())\n",
        "                labels = Variable(labels.cuda())\n",
        "\n",
        "            # Clear all accumulated gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Predict classes using images from the test set\n",
        "            outputs = model(images)\n",
        "            # Compute the loss based on the predictions and actual labels\n",
        "            #print(\"outputs \", outputs.shape,\" labels \",labels.shape)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # Backpropagate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Adjust parameters according to the computed gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # train_loss += loss.cpu().data[0] * images.size(0)\n",
        "            train_loss += loss.cpu().item() * images.size(0)\n",
        "            _, prediction = torch.max(outputs.data, 1)\n",
        "\n",
        "            train_acc += torch.sum(prediction == labels.data)\n",
        "\n",
        "        # Call the learning rate adjustment function\n",
        "        adjust_learning_rate(epoch)\n",
        "\n",
        "        # Compute the average acc and loss over all 50000 training images\n",
        "        train_acc = train_acc.cpu().numpy() / train_size\n",
        "        train_loss = train_loss / train_size\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        results = test()\n",
        "        test_acc = results[0]\n",
        "        test_acc_abs = results[1]\n",
        "\n",
        "            # Save the model if the test acc is greater than our current best\n",
        "        if test_acc_abs > best_acc and epoch > 1:\n",
        "                save_models(epoch,loss,str(test_acc_abs.cpu().numpy()))\n",
        "                best_acc = test_acc_abs\n",
        "\n",
        "            # Print the metrics\n",
        "        time_elapsed = time.time() - since\n",
        "        print(\"Epoch {}, Train Accuracy: {:.1%} , TrainLoss: {:.4f} , Test Accuracy: {:.1%},\"\n",
        "              \"Test Corrects: {}\".format(epoch, train_acc, train_loss, test_acc, test_acc_abs),\n",
        "              ' time {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600,(time_elapsed // 60) % 60, time_elapsed % 60))\n",
        "        # printm()\n",
        "        \n",
        "\n",
        "\n",
        "        # View_Test.test(model,deploy_test, validate_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    #  fixed prediction == labels.data,\n",
        "    #-------------------------------------------------------------------\n",
        "    load_latest_saved_model(\"Birdies_model_2__best_5_FDpsBSksFn_128_128_64_3_64.model\")\n",
        "    train(200)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "looking for  /content/drive/My Drive/Colab Notebooks/saved_models/Birdies_model_2__best_5_FDpsBSksFn_128_128_64_3_64.model\n",
            "exists =  True\n",
            "using saved model  /content/drive/My Drive/Colab Notebooks/saved_models/Birdies_model_2__best_5_FDpsBSksFn_128_128_64_3_64.model  Loss: 64.0000\n",
            "Optimizer's state_dict:\n",
            "param_groups \t [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False, 'params': [140310872795896, 140310870567024, 140310870567888, 140310871182792, 140312181521936, 140312181519128, 140312181518768, 140312181518408, 140310864146296, 140310864145288, 140310864146080, 140310864145648, 140310864146368, 140310864145936, 140310864146224, 140310864145720, 140310864146008, 140310864144928, 140310830362768, 140310830362912, 140310830363344, 140310830363416, 140310830363560, 140310830363704, 140310830364136, 140310830364208, 140310830364352, 140310830364496, 140310830365000, 140310830365072, 140310830365216, 140310830365360, 140310830365792, 140310830365864, 140310830366008, 140310830366152, 140310830366584, 140310830366656, 140310830416016, 140310830416160, 140310830416592, 140310830416664, 140310830416808, 140310830416952, 140310830417456, 140310830417528, 140310830417672, 140310830417816, 140310830418248, 140310830418320, 140310830418464, 140310830418608, 140310830419040, 140310830419112, 140310830419256, 140310830419400, 140310830419760, 140310830419832]}]\n",
            "learning rate adjusted to  0.0001\n",
            "model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}